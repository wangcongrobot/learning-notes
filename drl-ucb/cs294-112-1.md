# 2 Supervised Learning of Behaviors

### Today's Lecture
1. Definition of sequential decision problems
2. Imitation learning: supervised learning for decision making
   1. Dose direct imitation work?
   2. How can we make it work more often?
3. Case studies of recent work in (deep) imitation learning
4. What is missing from imitation learning?
- Goals:
  - Understand definitions & notation
  - Understand basic imitation learning algorithms
  - Understand their strengths & weaknesses

### Terminology & notation

$\bold{s_t}-state$
$\bold{o_t}-observation$
$\bold{a_t}-action$
$\pi_\theta(\bold{a_t}|\bold{o_t})-policy$
$\pi_\theta(\bold{a_t}|\bold{s_t})-policy\space (fully\space observed)$

### Imitation Learning
$\bold{o_t}\rightarrow\pi_\theta(\bold{a_t}|\bold{o_t})\rightarrow\bold{a_t}$

behavior cloning:
$\bold{o_t},\bold{a_t}$ $\rightarrow$ training data $\rightarrow$ supervised learning $\pi_\theta(\bold{a_t}|\bold{o_t})$



## Tensorflow

Train an agent to perform useful tasks

$$\theta^\star=arg\underset{\theta}{\mathsf{min}}\underset{(\bold{x,y})\in\mathcal{D}}{\sum}{||f_\theta(\bold{x})-\bold{y}||}$$

$arg\underset{\theta}{\mathsf{min}}$ : gradient descent
$f_\theta(\bold{x})$ : neural networks

What is Tensorflow?
- Library for
  - Defining computation graphs (User define)
  - Calculating gradients (TF calculates)



$\nabla_{\theta}J(\theta)=E_{\tau\sim\pi_{\theta}(\tau)}[\nabla_{\theta}log\pi_\theta(\tau)r(\tau)]$