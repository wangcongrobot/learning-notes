# Reward in RL


## Example

https://github.com/deepmind/dm_control/blob/master/dm_control/utils/rewards.py

- [Learning values across many orders of magnitude](https://arxiv.org/pdf/1602.07714.pdf)

- [Why does is make sense to normalize rewards per episode in reinforcement learning](https://ai.stackexchange.com/questions/10196/why-does-is-make-sense-to-normalize-rewards-per-episode-in-reinforcement-learnin/10200#10200)


## Scale Reward

https://www.coursera.org/lecture/practical-rl/reward-design-e5sNr


## Reward design

- [Thoughts on reward engineering](https://ai-alignment.com/thoughts-on-reward-engineering-82b193ec03f6)

- [Reward Engineering for Object Pick and Place Training](https://arxiv.org/pdf/2001.03792.pdf)